[2022-12-29 04:04:34,864] 15 root -INFO ->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Data Ingestion <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[2022-12-29 04:04:34,864] 23 root -INFO -Exporting Collection data as Pandas Dataframe
[2022-12-29 04:04:34,864] 16 root -INFO -Reading data from database:aps and collection: sensor
[2022-12-29 04:04:38,299] 18 root -INFO -Found columns:Index(['_id', 'class', 'aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000',
       'af_000', 'ag_000', 'ag_001',
       ...
       'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008',
       'ee_009', 'ef_000', 'eg_000'],
      dtype='object', length=172)
[2022-12-29 04:04:38,300] 20 root -INFO -Dropping column: _id
[2022-12-29 04:04:38,495] 22 root -INFO -Row and columns in df:(36188, 171)
[2022-12-29 04:04:38,495] 25 root -INFO -Save  data in feature store
[2022-12-29 04:04:39,016] 34 root -INFO -save df to feature store folder
[2022-12-29 04:04:41,357] 40 root -INFO -split dataset into train and test set
[2022-12-29 04:04:41,896] 43 root -INFO -Creating dataset directory folder if not available
[2022-12-29 04:04:41,896] 48 root -INFO -save df to feature store folder
[2022-12-29 04:04:43,975] 57 root -INFO -Data ingestion artifact:DataIngestionArtifact(feature_store_file_path='/config/workspace/artifact/12292022_040434/data_ingestion/feature_store', train_file_path='/config/workspace/artifact/12292022_040434/data_ingestion/dataset/train.csv', test_file_path='/config/workspace/artifact/12292022_040434/data_ingestion/dataset/test.csv')
[2022-12-29 04:04:44,409] 14 root -INFO ->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Data Validation <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[2022-12-29 04:04:44,409] 106 root -INFO -Reading base dataframe
[2022-12-29 04:04:47,263] 109 root -INFO -Replace na valuse in  base dataframe
[2022-12-29 04:04:48,185] 39 root -INFO -selecting columns names which contains null values more than threshold 0.2
[2022-12-29 04:04:48,186] 42 root -INFO -columns to drop :Index(['ab_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000',
       'bq_000', 'br_000', 'cr_000'],
      dtype='object')
[2022-12-29 04:04:48,270] 112 root -INFO -dropped in  base dataframe
[2022-12-29 04:04:48,270] 114 root -INFO -Reading train dataframe
[2022-12-29 04:04:48,659] 116 root -INFO -Reading test dataframe
[2022-12-29 04:04:48,760] 119 root -INFO -drop ull value colums in  train dataframe
[2022-12-29 04:04:48,772] 39 root -INFO -selecting columns names which contains null values more than threshold 0.2
[2022-12-29 04:04:48,772] 42 root -INFO -columns to drop :Index(['ab_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000',
       'bq_000', 'br_000', 'cr_000'],
      dtype='object')
[2022-12-29 04:04:48,782] 121 root -INFO -drop ull value colums in  test dataframe
[2022-12-29 04:04:48,786] 39 root -INFO -selecting columns names which contains null values more than threshold 0.2
[2022-12-29 04:04:48,787] 42 root -INFO -columns to drop :Index(['ab_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000',
       'bq_000', 'br_000', 'cr_000'],
      dtype='object')
[2022-12-29 04:04:55,879] 131 root -INFO -is all required columns present train dataframe
[2022-12-29 04:04:55,879] 133 root -INFO -is all required columns present test dataframe
[2022-12-29 04:04:55,879] 137 root -INFO -As all columns are avialable in train df hence detecting data drift 
[2022-12-29 04:04:58,835] 140 root -INFO -As all columns are avialable in test df hence detecting data drift 
[2022-12-29 04:05:00,085] 144 root -INFO -Write a report in yaml file
[2022-12-29 04:05:00,127] 148 root -INFO -Data Validataion artifact:DataValidationArtifact(report_file_path='/config/workspace/artifact/12292022_040434/data_validation/report.yaml') 
